{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Verma's\\AppData\\Local\\Temp\\ipykernel_15528\\1247821241.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets_4123_6408_framingham.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #to find no. of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('education',axis=1,inplace=True)#axis 1 for column and inplace true for hamesha k liye rkhne k liye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fill missing valuse and delete use less data\n",
    "df.isnull().sum() # this tells missing data in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill the binary values with mode funciton means jo jyda repeat ho rhi ho valuse\n",
    "#fill the continuous columns wiht meadian values \n",
    "# Define the binary columns\n",
    "bin_cols = [\"male\", \"currentSmoker\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\"]\n",
    "\n",
    "# Fill missing values for binary features with the most frequent value (mode)\n",
    "for col in bin_cols:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df.fillna({col: mode_val}, inplace=True)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Fill missing values for numeric features\n",
    "numeric_cols = [\"cigsPerDay\", \"BPMeds\", \"totChol\", \"BMI\", \"heartRate\", \"glucose\"]\n",
    "for col in numeric_cols:\n",
    "    median_val = df[col].median()\n",
    "    df.fillna({col:median_val}, inplace=True)\n",
    "\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "df.isnull().sum() #see now no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1     644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced dataset \n",
    "df['TenYearCHD'].value_counts()#as here 0 have more values then 1 so we have to balance the dataset to make a good model\n",
    "#we have three ways oversampling undersampling smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the data\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['TenYearCHD'] == 0] #extrating 0 values\n",
    "df_minority = df[df['TenYearCHD'] == 1] #extrating 1 values\n",
    "\n",
    "#here we are doing oversampling\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # To match majority class\n",
    "                                 random_state=42) # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1    3596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now splitting the data in train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_balanced.drop(columns=['TenYearCHD']) # only input values\n",
    "y = df_balanced['TenYearCHD'] # output values\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#0.2 means x 20% data utha k x_test ko de dega and same with y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>29.67</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>21.64</td>\n",
       "      <td>75.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>27.91</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>23.07</td>\n",
       "      <td>82.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>29.35</td>\n",
       "      <td>77.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>24.42</td>\n",
       "      <td>72.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.72</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>234.0</td>\n",
       "      <td>114.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>28.62</td>\n",
       "      <td>75.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>279.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>30.63</td>\n",
       "      <td>80.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5753 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "1905     0   64              0         0.0     0.0                0   \n",
       "2075     0   37              1        20.0     0.0                0   \n",
       "1128     0   63              1        10.0     0.0                0   \n",
       "1782     0   65              0         0.0     0.0                0   \n",
       "241      1   65              1        15.0     0.0                0   \n",
       "...    ...  ...            ...         ...     ...              ...   \n",
       "624      1   63              1        20.0     0.0                0   \n",
       "485      1   54              1        40.0     0.0                0   \n",
       "4232     1   68              0         0.0     0.0                0   \n",
       "952      1   66              1        30.0     0.0                0   \n",
       "1030     1   45              1        20.0     0.0                0   \n",
       "\n",
       "      prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \n",
       "1905             1         0    229.0  145.0   85.0  29.67       70.0     74.0  \n",
       "2075             0         0    166.0  112.0   73.5  21.64       75.0     93.0  \n",
       "1128             1         0    236.0  189.0  103.0  27.91       60.0     74.0  \n",
       "1782             1         0    245.0  171.0   89.0  23.07       82.0     93.0  \n",
       "241              1         0    219.0  148.0   90.0  29.35       77.0     97.0  \n",
       "...            ...       ...      ...    ...    ...    ...        ...      ...  \n",
       "624              1         0    269.0  180.0  101.0  24.42       72.0     84.0  \n",
       "485              0         0    230.0  145.0   90.0  25.72       75.0     85.0  \n",
       "4232             1         0    176.0  168.0   97.0  23.14       60.0     79.0  \n",
       "952              0         1    234.0  114.5   62.5  28.62       75.0    216.0  \n",
       "1030             0         1    279.0  138.0   86.0  30.63       80.0    144.0  \n",
       "\n",
       "[5753 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#now here in tochol etc columns m some values are very large some values are small so we'll use scaler to bring these values to 0-1 \n",
    "#because vrna model large value ko more importance deta h\n",
    "#two techniques minmax scaler and standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94172615,  1.4582083 , -1.02624378, ...,  0.840088  ,\n",
       "        -0.50731448, -0.34072887],\n",
       "       [-0.94172615, -1.66694628,  0.97442734, ..., -1.050363  ,\n",
       "        -0.0898974 ,  0.25133934],\n",
       "       [-0.94172615,  1.34246184,  0.97442734, ...,  0.42574258,\n",
       "        -1.34214864, -0.34072887],\n",
       "       ...,\n",
       "       [ 1.06187982,  1.92119417, -1.02624378, ..., -0.6972277 ,\n",
       "        -1.34214864, -0.18492145],\n",
       "       [ 1.06187982,  1.68970124,  0.97442734, ...,  0.59289329,\n",
       "        -0.0898974 ,  4.08420194],\n",
       "       [ 1.06187982, -0.74097455,  0.97442734, ...,  1.0660946 ,\n",
       "         0.32751968,  1.84057505]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled#numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE WILL BE TRAINING WITH 10 DIFFERENT MODELS AND DIFFERENT METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy: 0.9722029186935371\n",
      "Classification Report for RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       735\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for RandomForestClassifier:\n",
      "[[700  35]\n",
      " [  5 699]]\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Verma's\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier Accuracy: 0.6719944405837387\n",
      "Classification Report for AdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       735\n",
      "           1       0.66      0.68      0.67       704\n",
      "\n",
      "    accuracy                           0.67      1439\n",
      "   macro avg       0.67      0.67      0.67      1439\n",
      "weighted avg       0.67      0.67      0.67      1439\n",
      "\n",
      "Confusion Matrix for AdaBoostClassifier:\n",
      "[[486 249]\n",
      " [223 481]]\n",
      "==================================================\n",
      "GradientBoostingClassifier Accuracy: 0.7289784572619875\n",
      "Classification Report for GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       735\n",
      "           1       0.70      0.77      0.74       704\n",
      "\n",
      "    accuracy                           0.73      1439\n",
      "   macro avg       0.73      0.73      0.73      1439\n",
      "weighted avg       0.73      0.73      0.73      1439\n",
      "\n",
      "Confusion Matrix for GradientBoostingClassifier:\n",
      "[[508 227]\n",
      " [163 541]]\n",
      "==================================================\n",
      "LogisticRegression Accuracy: 0.6587908269631688\n",
      "Classification Report for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       735\n",
      "           1       0.65      0.66      0.66       704\n",
      "\n",
      "    accuracy                           0.66      1439\n",
      "   macro avg       0.66      0.66      0.66      1439\n",
      "weighted avg       0.66      0.66      0.66      1439\n",
      "\n",
      "Confusion Matrix for LogisticRegression:\n",
      "[[481 254]\n",
      " [237 467]]\n",
      "==================================================\n",
      "SVC Accuracy: 0.6831132731063239\n",
      "Classification Report for SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       735\n",
      "           1       0.67      0.70      0.68       704\n",
      "\n",
      "    accuracy                           0.68      1439\n",
      "   macro avg       0.68      0.68      0.68      1439\n",
      "weighted avg       0.68      0.68      0.68      1439\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[493 242]\n",
      " [214 490]]\n",
      "==================================================\n",
      "KNeighborsClassifier Accuracy: 0.7873523280055594\n",
      "Classification Report for KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       735\n",
      "           1       0.72      0.92      0.81       704\n",
      "\n",
      "    accuracy                           0.79      1439\n",
      "   macro avg       0.81      0.79      0.78      1439\n",
      "weighted avg       0.81      0.79      0.78      1439\n",
      "\n",
      "Confusion Matrix for KNeighborsClassifier:\n",
      "[[482 253]\n",
      " [ 53 651]]\n",
      "==================================================\n",
      "DecisionTreeClassifier Accuracy: 0.9145239749826268\n",
      "Classification Report for DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91       735\n",
      "           1       0.85      1.00      0.92       704\n",
      "\n",
      "    accuracy                           0.91      1439\n",
      "   macro avg       0.92      0.92      0.91      1439\n",
      "weighted avg       0.93      0.91      0.91      1439\n",
      "\n",
      "Confusion Matrix for DecisionTreeClassifier:\n",
      "[[615 120]\n",
      " [  3 701]]\n",
      "==================================================\n",
      "GaussianNB Accuracy: 0.5830437804030577\n",
      "Classification Report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       735\n",
      "           1       0.72      0.24      0.36       704\n",
      "\n",
      "    accuracy                           0.58      1439\n",
      "   macro avg       0.64      0.58      0.53      1439\n",
      "weighted avg       0.64      0.58      0.53      1439\n",
      "\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[668  67]\n",
      " [533 171]]\n",
      "==================================================\n",
      "XGBClassifier Accuracy: 0.906184850590688\n",
      "Classification Report for XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       735\n",
      "           1       0.86      0.96      0.91       704\n",
      "\n",
      "    accuracy                           0.91      1439\n",
      "   macro avg       0.91      0.91      0.91      1439\n",
      "weighted avg       0.91      0.91      0.91      1439\n",
      "\n",
      "Confusion Matrix for XGBClassifier:\n",
      "[[625 110]\n",
      " [ 25 679]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'F1-Score', 'Precision', 'Recall'])\n",
    "\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{clf_name} Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"Classification Report for {clf_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(f\"Confusion Matrix for {clf_name}:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9715079916608756\n",
      "Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       735\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[699  36]\n",
      " [  5 699]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report for Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  0\n",
      "actual class  0\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06187982, -1.78269275,  0.97442734,  0.81185379, -0.20499115,\n",
       "        -0.09734139, -0.79968646, -0.21580282,  0.02868136, -0.76044968,\n",
       "         0.00286132, -0.48534651,  0.16055284,  0.56295418]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[200].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[200].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving files because we have to use in website\n",
    "#we will save two things one our model and one scaler that we use\n",
    "#we will use pickel for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_classifier,open(\"model/rf_classifier.pkl\",'wb'))\n",
    "pickle.dump(scaler,open(\"model/scaler.pkl\",'wb'))\n",
    "#wb => write binary mode rb=> read binary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RandomForestClassifier model\n",
    "with open(\"model/rf_classifier.pkl\", \"rb\") as file:\n",
    "    rf_classifier = pickle.load(file)\n",
    "\n",
    "# Load the scaler\n",
    "with open(\"model/scaler.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKING PREDICTOR FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll make a funciton firstly it will encode yes no male female valuse to 0 and 1\n",
    "#then convert the values to array using np.array\n",
    "#then scale the values scaler.transform\n",
    "#then predict the answer model_name.predict(scaled_features)\n",
    "def predict(model, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose):\n",
    "    # Encode categorical variables\n",
    "    male_encoded = 1 if male.lower() == \"male\" else 0\n",
    "    currentSmoker_encoded = 1 if currentSmoker.lower() == \"yes\" else 0\n",
    "    BPMeds_encoded = 1 if BPMeds.lower() == \"yes\" else 0\n",
    "    prevalentStroke_encoded = 1 if prevalentStroke.lower() == \"yes\" else 0\n",
    "    prevalentHyp_encoded = 1 if prevalentHyp.lower() == \"yes\" else 0\n",
    "    diabetes_encoded = 1 if diabetes.lower() == \"yes\" else 0\n",
    "    \n",
    "    # Prepare features array\n",
    "    features = np.array([[male_encoded, age, currentSmoker_encoded, cigsPerDay, BPMeds_encoded, prevalentStroke_encoded, prevalentHyp_encoded, diabetes_encoded, totChol, sysBP, diaBP, BMI, heartRate, glucose]])\n",
    "    \n",
    "    # scalling\n",
    "    scaled_features = scaler.transform(features)\n",
    "    \n",
    "    # predict by model\n",
    "    result = model.predict(scaled_features)\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patiennt has No Heart Deseas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Verma's\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "male = \"female\"\n",
    "age = 56.00\n",
    "currentSmoker = \"yes\"\n",
    "cigsPerDay = 3.00\n",
    "BPMeds = \"no\"\n",
    "prevalentStroke = \"no\"\n",
    "prevalentHyp = \"yes\"\n",
    "diabetes = 'no'\n",
    "totChol = 285.00\n",
    "sysBP = 145.00\n",
    "diaBP = 100.00\n",
    "BMI = 30.14\n",
    "heartRate = 80.00\n",
    "glucose = 86.00\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Diseas\")\n",
    "else: \n",
    "    print(\"The Patiennt has No Heart Deseas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO NOW WE HAVE PREPROCESSED TRAIN TEST METRICS EVALUATE PREDICT THE DATA \n",
    "NOW MOVING TO MAKE GUI PART OF THE PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1.post1'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
